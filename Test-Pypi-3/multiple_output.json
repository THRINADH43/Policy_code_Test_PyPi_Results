{'model': 'temp_model_123_3',
 'model_version': 'v1',
 'dataset': 'temp_123_3',
 'dataset_version': 'v1',
 'result': [{'complete': {'complete': {'operational': {'accuracy': 'pass',
      'precision': 'pass',
      'recall': 'fail',
      'f1': 'fail'},
     'fairness': {'balanced_accuracy': 'fail',
      'balanced_acc_error': 'fail',
      'demographic_parity_difference': 'fail'},
     'operational_scores': {'accuracy': '0.7902857142857143',
      'precision': '0.8011192423590185',
      'recall': '0.5168008886420439',
      'f1': '0.6282916948008103'},
     'fairness_scores': {'balanced_accuracy': '0.7941636324305794',
      'balanced_acc_error': '0.009249067740303738',
      'demographic_parity_difference': '0.05995385011830301'},
     'operational_thresholds': {'accuracy': '0.7',
      'precision': '0.8',
      'recall': '0.8',
      'f1': '0.7'},
     'fairness_thresholds': {'balanced_accuracy': '0.8',
      'balanced_acc_error': '0.7',
      'demographic_parity_difference': '0.8'}}},
   'subsets': {(('sex', 'male'),
     ('race', 'African')): {'operational': {'accuracy': 'pass',
      'precision': 'pass',
      'recall': 'fail',
      'f1': 'pass'}, 'fairness': {'balanced_accuracy': 'pass',
      'balanced_acc_error': 'fail'}, 'operational_scores': {'accuracy': '0.8600999286224126',
      'precision': '0.8484848484848485',
      'recall': '0.6859688195991092',
      'f1': '0.7586206896551725'}, 'fairness_scores': {'balanced_accuracy': '0.8563233490979156',
      'balanced_acc_error': '0.02118350869004815'}, 'operational_thresholds': {'accuracy': '0.7',
      'precision': '0.8',
      'recall': '0.8',
      'f1': '0.7'}, 'fairness_thresholds': {'balanced_accuracy': '0.8',
      'balanced_acc_error': '0.7'}},
    (('sex', 'male'),
     ('race', 'American')): {'operational': {'accuracy': 'pass',
      'precision': 'pass',
      'recall': 'fail',
      'f1': 'pass'}, 'fairness': {'balanced_accuracy': 'pass',
      'balanced_acc_error': 'fail'}, 'operational_scores': {'accuracy': '0.8390804597701149',
      'precision': '0.8393939393939394',
      'recall': '0.6183035714285714',
      'f1': '0.712082262210797'}, 'fairness_scores': {'balanced_accuracy': '0.8391884951206985',
      'balanced_acc_error': '0.022682804847256332'}, 'operational_thresholds': {'accuracy': '0.7',
      'precision': '0.8',
      'recall': '0.8',
      'f1': '0.7'}, 'fairness_thresholds': {'balanced_accuracy': '0.8',
      'balanced_acc_error': '0.7'}},
    (('sex', 'female'),
     ('race', 'American')): {'operational': {'accuracy': 'pass',
      'precision': 'fail',
      'recall': 'fail',
      'f1': 'fail'}, 'fairness': {'balanced_accuracy': 'fail',
      'balanced_acc_error': 'fail'}, 'operational_scores': {'accuracy': '0.7495256166982922',
      'precision': '0.7835990888382688',
      'recall': '0.44272844272844275',
      'f1': '0.5657894736842106'}, 'fairness_scores': {'balanced_accuracy': '0.7620811501710817',
      'balanced_acc_error': '0.021943778380310433'}, 'operational_thresholds': {'accuracy': '0.7',
      'precision': '0.8',
      'recall': '0.8',
      'f1': '0.7'}, 'fairness_thresholds': {'balanced_accuracy': '0.8',
      'balanced_acc_error': '0.7'}},
    (('sex', 'female'),
     ('race', 'African')): {'operational': {'accuracy': 'pass',
      'precision': 'fail',
      'recall': 'fail',
      'f1': 'fail'}, 'fairness': {'balanced_accuracy': 'fail',
      'balanced_acc_error': 'fail'}, 'operational_scores': {'accuracy': '0.7489280609814197',
      'precision': '0.7172557172557172',
      'recall': '0.46875',
      'f1': '0.5669679539852095'}, 'fairness_scores': {'balanced_accuracy': '0.7377996756859551',
      'balanced_acc_error': '0.022665006579405667'}, 'operational_thresholds': {'accuracy': '0.7',
      'precision': '0.8',
      'recall': '0.8',
      'f1': '0.7'}, 'fairness_thresholds': {'balanced_accuracy': '0.8',
      'balanced_acc_error': '0.7'}},
    (('sex', 'female'),
     ('race', 'Indian')): {'operational': {'accuracy': 'pass',
      'precision': 'pass',
      'recall': 'fail',
      'f1': 'fail'}, 'fairness': {'balanced_accuracy': 'fail',
      'balanced_acc_error': 'fail'}, 'operational_scores': {'accuracy': '0.7611869995289684',
      'precision': '0.8018648018648019',
      'recall': '0.4490861618798956',
      'f1': '0.5757322175732219'}, 'fairness_scores': {'balanced_accuracy': '0.7763751400115037',
      'balanced_acc_error': '0.02148787390423279'}, 'operational_thresholds': {'accuracy': '0.7',
      'precision': '0.8',
      'recall': '0.8',
      'f1': '0.7'}, 'fairness_thresholds': {'balanced_accuracy': '0.8',
      'balanced_acc_error': '0.7'}},
    (('sex', 'male'),
     ('race', 'Indian')): {'operational': {'accuracy': 'pass',
      'precision': 'pass',
      'recall': 'fail',
      'f1': 'fail'}, 'fairness': {'balanced_accuracy': 'pass',
      'balanced_acc_error': 'fail'}, 'operational_scores': {'accuracy': '0.8402323892519971',
      'precision': '0.8647686832740213',
      'recall': '0.571764705882353',
      'f1': '0.6883852691218131'}, 'fairness_scores': {'balanced_accuracy': '0.8493551445567187',
      'balanced_acc_error': '0.02282628571648792'}, 'operational_thresholds': {'accuracy': '0.7',
      'precision': '0.8',
      'recall': '0.8',
      'f1': '0.7'}, 'fairness_thresholds': {'balanced_accuracy': '0.8',
      'balanced_acc_error': '0.7'}}}}]}